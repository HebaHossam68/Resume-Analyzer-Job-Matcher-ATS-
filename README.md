# ğŸ“„ Resume Analyzer & Job Matching System

An AI-powered system that analyzes resumes (CVs) and job descriptions, extracts structured skills using Large Language Models (LLMs), and computes a matching score with clear, actionable insights.

This project is designed with **clean architecture**, **modular services**, and **production-ready structure**, making it suitable for real-world deployment and academic or professional portfolios.

---

## ğŸ“‘ Table of Contents

* [Features](#-features)
* [Tech Stack](#-tech-stack)
* [Project Structure](#-project-structure)
* [Installation](#-installation)
* [How to Run Using Streamlit](#-how-to-run-using-streamlit)
* [How It Works](#-how-it-works)
* [API Overview](#-api-overview)
* [Future Improvements](#-future-improvements)

---

## âœ¨ Features

* ğŸ“„ Upload and parse **PDF resumes**
* ğŸ“ Analyze **job descriptions** (text-based)
* ğŸ¤– Skill extraction using **LLMs (Mistral / Transformers)**
* ğŸ§  Structured skill categorization:

  * Programming Languages
  * Frameworks & Libraries
  * Tools & Platforms
  * Domain Knowledge
  * Technical Concepts
  * Soft Skills
* ğŸ“Š Skill matching with:

  * Exact match
  * Partial match
  * Missing skills
* ğŸ¯ Final matching score & decision
* ğŸ“‹ Human-readable recommendation report
* âš™ï¸ Modular, scalable project architecture

---

## ğŸ§° Tech Stack

### Backend

* **FastAPI** â€“ API framework
* **Uvicorn** â€“ ASGI server

### AI & NLP

* **Transformers (HuggingFace)**
* **PyTorch**
* **LangChain**
* **Mistral Instruct Models**

### Data & Parsing

* **PDFPlumber** â€“ PDF text extraction
* **Pandas / NumPy** â€“ Data processing

### Frontend

* **Streamlit** â€“ Interactive UI

---

## ğŸ—‚ Project Structure

```bash
resume-analyzer/
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ main.py                  # FastAPI entry point
â”‚
â”œâ”€â”€ core/
â”‚   â””â”€â”€ llm_engine.py             # Model loading & text generation
â”‚               
â”‚
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ FastAPI_code.py           # FastAPI app setup
â”‚   â””â”€â”€ ngrok.py                  # ngrok tunnel setup
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ cv_schema.py              # CV output schema
â”‚   â””â”€â”€ job_description_schema.py # JD output schema
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ read_resume.py            # Resume reading & preprocessing
â”‚   â””â”€â”€ read_jobDescription.py    # Job description handling
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ constants.py              # Shared constants
â”‚   â”œâ”€â”€ json_extractor.py         # Robust JSON parsing from LLM output
â”‚   â””â”€â”€ text_utils.py             # Text normalization & helpers
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/HebaHossam68/Resume-Analyzer-Job-Matcher-ATS-.git
cd resume-analyzer
```

### 2ï¸âƒ£ Create Virtual Environment (Recommended)

```bash
python -m venv venv
source venv/bin/activate  # Linux / Mac
venv\\Scripts\\activate     # Windows
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ How to Run Using Streamlit

```bash
streamlit run app/main.py
```

Then open your browser at:

```
http://localhost:8001
```

---

## ğŸ”„ How It Works

1. User uploads a **CV (PDF)** and enters a **Job Description**
2. Text is extracted and cleaned
3. LLM extracts structured skills using strict JSON schema
4. Skills are normalized and compared
5. Matching table and final score are generated
6. Results are displayed via API or Streamlit UI

---

## ğŸ”Œ API Overview

### `POST /analyze`

**Inputs:**

* CV file (PDF)
* Job description text

**Response:**

```json
{
  "final_score": 24.0,
  "decision": "Needs Improvement âš ï¸",
  "recommendation": "âŒ Not a good fit",

  "matching_table": [
    {
      "Skill": "Python",
      "Status": "âœ… Match",
      "Action Needed": "No Action Needed"
    },
    {
      "Skill": "Javascript",
      "Status": "âœ… Match",
      "Action Needed": "No Action Needed"
    },
    {
      "Skill": "Django",
      "Status": "âŒ Missing",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Flask",
      "Status": "âœ… Match",
      "Action Needed": "No Action Needed"
    },
    {
      "Skill": "Restful Apis",
      "Status": "âŒ Missing",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Microservices",
      "Status": "âŒ Missing",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Postgresql",
      "Status": "âŒ Missing",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Mysql",
      "Status": "âŒ Missing",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Aws",
      "Status": "âŒ Missing",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Azure",
      "Status": "ğŸŸ¡ Partial",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Docker",
      "Status": "âŒ Missing",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Ci/Cd",
      "Status": "âŒ Missing",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Data Structures",
      "Status": "âœ… Match",
      "Action Needed": "No Action Needed"
    },
    {
      "Skill": "Problem Solving",
      "Status": "âŒ Missing",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Communication",
      "Status": "âŒ Missing",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Teamwork",
      "Status": "âŒ Missing",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Software Engineering",
      "Status": "âœ… Match",
      "Action Needed": "No Action Needed"
    },
    {
      "Skill": "Kubernetes",
      "Status": "âŒ Missing",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Terraform",
      "Status": "âŒ Missing",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Devops",
      "Status": "âŒ Missing",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Container Orchestration",
      "Status": "âŒ Missing",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Iac",
      "Status": "âŒ Missing",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Serverless",
      "Status": "âŒ Missing",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Aws Lambda",
      "Status": "âŒ Missing",
      "Action Needed": "Improve / Learn"
    },
    {
      "Skill": "Api Gateway",
      "Status": "ğŸŸ¡ Partial",
      "Action Needed": "Improve / Learn"
    }
  ],

  "summary_table": [
    {
      "Match Type": "Yes",
      "Count": 5
    },
    {
      "Match Type": "Partial",
      "Count": 2
    },
    {
      "Match Type": "No",
      "Count": 18
    }
  ]
}

```

---

## ğŸš€ Future Improvements

* ğŸ” Semantic matching using embeddings (FAISS)
* ğŸ“ˆ Explainable AI insights per missing skill
* ğŸŒ Cloud deployment (AWS / GCP)
* ğŸ³ Dockerization
* ğŸ” Authentication & user profiles
* ğŸ“Š Dashboard analytics

---

## ğŸ‘©â€ğŸ’» Author

**Heba Hossam**
AI & Data Science Engineer | MSc Computer Science

---

â­ If you find this project helpful, please consider giving it a star on GitHub!
